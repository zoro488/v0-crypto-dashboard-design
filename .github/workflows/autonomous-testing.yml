name: ğŸ¤– CHRONOS Autonomous Testing

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  schedule:
    # Ejecutar cada 6 horas
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      max_iterations:
        description: 'MÃ¡ximo de iteraciones del agente'
        required: false
        default: '30'
      target_score:
        description: 'Score objetivo (0-100)'
        required: false
        default: '100'

env:
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'
  PNPM_VERSION: '8'

jobs:
  # Job 1: VerificaciÃ³n de tipos TypeScript
  typescript-check:
    name: ğŸ“˜ TypeScript Check
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ğŸ“¥ Install dependencies
        run: pnpm install --frozen-lockfile

      - name: ğŸ” TypeScript type check
        run: pnpm type-check
        continue-on-error: true

      - name: ğŸ“Š Upload TypeScript results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: typescript-results
          path: |
            *.log
            tsconfig.json

  # Job 2: Tests de Jest
  jest-tests:
    name: ğŸ§ª Jest Tests
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ğŸ“¥ Install dependencies
        run: pnpm install --frozen-lockfile

      - name: ğŸ§ª Run Jest tests
        run: pnpm test --passWithNoTests --coverage
        continue-on-error: true

      - name: ğŸ“Š Upload coverage
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: jest-coverage
          path: coverage/

  # Job 3: Tests de evaluaciÃ³n Python
  python-evaluation:
    name: ğŸ Python Evaluation
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ğŸ“¥ Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r evaluation/requirements.txt || pip install pandas numpy

      - name: ğŸ§ª Run evaluation tests
        run: |
          cd evaluation
          python test_evaluators.py
        continue-on-error: true

      - name: ğŸ“Š Run full evaluation
        run: |
          cd evaluation
          python run_evaluation.py --service all
        continue-on-error: true

      - name: ğŸ“Š Upload evaluation results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: evaluation-results
          path: evaluation/results/

  # Job 4: ValidaciÃ³n de lÃ³gica de negocio
  business-logic:
    name: ğŸ’¼ Business Logic Validation
    runs-on: ubuntu-latest
    needs: [python-evaluation]
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¥ Install dependencies
        run: |
          pip install pandas numpy

      - name: ğŸ’¼ Validate business logic
        run: |
          cd evaluation
          python -c "
          import sys
          sys.path.insert(0, '.')
          from evaluators.business_logic import BusinessLogicEvaluator
          
          evaluator = BusinessLogicEvaluator()
          
          # Test de distribuciÃ³n de ventas (fÃ³rmula correcta del sistema CHRONOS)
          test_cases = [
              {'precioVenta': 10000, 'precioCompra': 6300, 'precioFlete': 500, 'cantidad': 10},
              {'precioVenta': 15000, 'precioCompra': 9000, 'precioFlete': 600, 'cantidad': 5},
              {'precioVenta': 8000, 'precioCompra': 5000, 'precioFlete': 400, 'cantidad': 20},
          ]
          
          passed = 0
          for tc in test_cases:
              expected_boveda = tc['precioCompra'] * tc['cantidad']
              expected_fletes = tc['precioFlete'] * tc['cantidad']
              expected_utilidades = (tc['precioVenta'] - tc['precioCompra'] - tc['precioFlete']) * tc['cantidad']
              
              result = evaluator(
                  operation_type='venta',
                  input_data=tc,
                  output_data={
                      'distribucion': {
                          'boveda_monte': expected_boveda,
                          'fletes': expected_fletes,
                          'utilidades': expected_utilidades
                      },
                      'total': tc['precioVenta'] * tc['cantidad']
                  }
              )
              
              if result.get('distribution_accuracy', 0) == 1.0:
                  passed += 1
                  print(f'âœ… Test passed: {tc}')
              else:
                  print(f'âŒ Test failed: {tc}')
                  print(f'   Result: {result}')
          
          print(f'\\nğŸ“Š Business Logic: {passed}/{len(test_cases)} tests passed')
          
          if passed < len(test_cases):
              sys.exit(1)
          "

  # Job 5: ValidaciÃ³n de datos CSV
  data-validation:
    name: ğŸ“Š Data Validation
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¥ Install pandas
        run: pip install pandas

      - name: ğŸ“Š Validate CSV data
        run: |
          python -c "
          import pandas as pd
          import os
          import sys
          
          csv_dir = 'csv'
          errors = []
          
          if not os.path.exists(csv_dir):
              print('âš ï¸ Directorio CSV no encontrado')
              sys.exit(0)
          
          csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]
          
          print(f'ğŸ“ Encontrados {len(csv_files)} archivos CSV')
          
          for csv_file in csv_files:
              filepath = os.path.join(csv_dir, csv_file)
              try:
                  df = pd.read_csv(filepath)
                  rows = len(df)
                  cols = len(df.columns)
                  print(f'  âœ… {csv_file}: {rows} filas, {cols} columnas')
              except Exception as e:
                  errors.append(f'{csv_file}: {e}')
                  print(f'  âŒ {csv_file}: Error - {e}')
          
          if errors:
              print(f'\\nâŒ {len(errors)} errores encontrados')
              sys.exit(1)
          else:
              print(f'\\nâœ… Todos los archivos CSV son vÃ¡lidos')
          "

  # Job 6: Agente autÃ³nomo
  autonomous-agent:
    name: ğŸ¤– Autonomous Agent
    runs-on: ubuntu-latest
    needs: [typescript-check, jest-tests, python-evaluation, business-logic, data-validation]
    if: always()
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸŸ¢ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: ğŸ“¥ Install all dependencies
        run: |
          pnpm install --frozen-lockfile
          pip install pandas numpy

      - name: ğŸ¤– Run Autonomous Testing Agent
        run: |
          python automation/autonomous_testing_agent.py
        env:
          MAX_ITERATIONS: ${{ github.event.inputs.max_iterations || '30' }}
          TARGET_SCORE: ${{ github.event.inputs.target_score || '100' }}
        continue-on-error: true

      - name: ğŸ“Š Upload agent reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: agent-reports
          path: |
            automation/reports/
            automation/logs/

  # Job 7: Reporte consolidado
  consolidated-report:
    name: ğŸ“‹ Consolidated Report
    runs-on: ubuntu-latest
    needs: [autonomous-agent]
    if: always()
    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ğŸ“¥ Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: ğŸ“‹ Generate consolidated report
        run: |
          echo "# ğŸ“‹ CHRONOS Testing Report" > report.md
          echo "" >> report.md
          echo "**Fecha:** $(date)" >> report.md
          echo "**Commit:** ${{ github.sha }}" >> report.md
          echo "**Branch:** ${{ github.ref_name }}" >> report.md
          echo "" >> report.md
          
          echo "## ğŸ“Š Resultados por Job" >> report.md
          echo "" >> report.md
          echo "| Job | Estado |" >> report.md
          echo "|-----|--------|" >> report.md
          echo "| TypeScript Check | ${{ needs.typescript-check.result || 'â“' }} |" >> report.md
          echo "| Jest Tests | ${{ needs.jest-tests.result || 'â“' }} |" >> report.md
          echo "| Python Evaluation | ${{ needs.python-evaluation.result || 'â“' }} |" >> report.md
          echo "| Business Logic | ${{ needs.business-logic.result || 'â“' }} |" >> report.md
          echo "| Data Validation | ${{ needs.data-validation.result || 'â“' }} |" >> report.md
          echo "| Autonomous Agent | ${{ needs.autonomous-agent.result || 'â“' }} |" >> report.md
          echo "" >> report.md
          
          echo "## ğŸ“ Artifacts" >> report.md
          ls -la artifacts/ 2>/dev/null || echo "No artifacts found"
          
          cat report.md

      - name: ğŸ“¤ Upload consolidated report
        uses: actions/upload-artifact@v4
        with:
          name: consolidated-report
          path: report.md

      - name: ğŸ’¬ Create Issue if tests fail
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const title = `ğŸš¨ Tests fallidos en ${context.ref}`;
            const body = `
            ## Detalles del fallo
            
            - **Commit:** ${context.sha}
            - **Branch:** ${context.ref}
            - **Workflow:** ${context.workflow}
            - **Run ID:** ${context.runId}
            
            ### Acciones recomendadas
            1. Revisar los logs del workflow
            2. Ejecutar tests localmente
            3. Aplicar correcciones necesarias
            
            [Ver detalles del workflow](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            `;
            
            // Buscar issue existente
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'automated-testing'
            });
            
            const existingIssue = issues.data.find(i => i.title === title);
            
            if (existingIssue) {
              // Actualizar issue existente
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: body
              });
            } else {
              // Crear nuevo issue
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['automated-testing', 'bug']
              });
            }
