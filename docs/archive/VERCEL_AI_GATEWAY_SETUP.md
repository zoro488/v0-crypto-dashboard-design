# üöÄ Vercel AI Gateway - Gu√≠a de Configuraci√≥n

Esta gu√≠a te ayudar√° a configurar y desplegar el sistema CHRONOS con Vercel AI Gateway.

## üìã Prerequisitos

- ‚úÖ Cuenta de Vercel (gratis o Pro)
- ‚úÖ Vercel CLI instalada (`npm i -g vercel`)
- ‚úÖ OpenAI API Key ([obtener aqu√≠](https://platform.openai.com/api-keys))
- ‚úÖ Firebase configurado

## üîß Paso 1: Configurar Variables de Entorno

### Opci√≥n A: Usando Vercel CLI (Recomendado)

```bash
# 1. Autenticarse en Vercel
vercel login

# 2. Vincular el proyecto
vercel link

# 3. Agregar OPENAI_API_KEY
vercel env add OPENAI_API_KEY
# Cuando pregunte:
# - Value: pega tu sk-proj-... de OpenAI
# - Environments: selecciona Production, Preview, Development (espacio para marcar)

# 4. Verificar variables
vercel env ls

# 5. Descargar variables localmente (opcional)
vercel env pull .env.local
```

### Opci√≥n B: Usando Dashboard de Vercel

1. Ve a [vercel.com/dashboard](https://vercel.com/dashboard)
2. Selecciona tu proyecto
3. Settings ‚Üí Environment Variables
4. Agregar:
   - **Name**: `OPENAI_API_KEY`
   - **Value**: `sk-proj-YOUR_KEY_HERE`
   - **Environments**: Production, Preview, Development

## üöÄ Paso 2: Desplegar a Vercel

### Deploy Autom√°tico (Recomendado)

```bash
# Deploy a producci√≥n
vercel --prod

# El comando har√°:
# ‚úÖ Build del proyecto
# ‚úÖ Optimizaci√≥n autom√°tica
# ‚úÖ Activaci√≥n de Vercel AI Gateway
# ‚úÖ Deploy a producci√≥n
```

### Deploy Manual

```bash
# 1. Build local (verificar que compila)
pnpm build

# 2. Preview deployment (staging)
vercel

# 3. Si todo funciona, promover a producci√≥n
vercel --prod
```

## üéØ Paso 3: Verificar Vercel AI Gateway

### ¬øQu√© hace Vercel AI Gateway autom√°ticamente?

‚úÖ **Caching Inteligente**
- Requests id√©nticas: 1 hora
- Embeddings: 7 d√≠as
- Tool calls: 30 minutos

‚úÖ **Rate Limiting**
- 100 req/min (Plan Pro)
- Auto retry con backoff

‚úÖ **Observabilidad**
- Dashboard con m√©tricas
- Latencia promedio
- Cache hit rate
- Costos por request

### Ver M√©tricas

1. Ve a [vercel.com/dashboard](https://vercel.com/dashboard)
2. Selecciona tu proyecto
3. Pesta√±a **AI** (solo en plan Pro)
4. Ver:
   - Total requests
   - Cache effectiveness
   - Average latency
   - Cost breakdown

## üß™ Paso 4: Probar el Chat AI

### En Desarrollo Local

```bash
# 1. Asegurar que .env.local tiene OPENAI_API_KEY
cat .env.local | grep OPENAI_API_KEY

# 2. Iniciar servidor
pnpm dev

# 3. Abrir navegador
open http://localhost:3000/ai-panel

# 4. Probar comandos:
# - "Mu√©strame las ventas de hoy"
# - "¬øCu√°nto dinero hay en B√≥veda Monte?"
# - "Registra una venta de..."
```

### En Producci√≥n

1. Ve a tu URL de Vercel: `https://tu-proyecto.vercel.app`
2. Login con Firebase Auth
3. Click en el √≠cono de IA (esquina inferior derecha)
4. Probar los 9 tools disponibles

## üõ†Ô∏è Troubleshooting

### Error: "OPENAI_API_KEY no configurada"

```bash
# Verificar que existe
vercel env ls | grep OPENAI_API_KEY

# Si no existe, agregarla
vercel env add OPENAI_API_KEY

# Re-deploy
vercel --prod
```

### Error: "Failed to fetch"

```bash
# Verificar que el endpoint existe
curl https://tu-proyecto.vercel.app/api/chat \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Hola"}]}'

# Debe retornar streaming response
```

### Rate Limit Alcanzado

Si est√°s en plan gratuito de Vercel:
- Upgrade a Pro ($20/mes)
- O usa caching m√°s agresivo
- O limita requests en el frontend

### Cache No Funciona

Vercel AI Gateway cache solo funciona:
- ‚úÖ En producci√≥n (no en `localhost`)
- ‚úÖ Con plan Pro o Enterprise
- ‚úÖ Si las requests son id√©nticas

## üìä Monitoreo

### Logs en Tiempo Real

```bash
# Ver logs de deployment
vercel logs

# Ver logs de una funci√≥n espec√≠fica
vercel logs --follow /api/chat
```

### M√©tricas Clave

Monitor en Vercel Dashboard:
- **Latency P95**: Debe ser < 2s
- **Error Rate**: Debe ser < 1%
- **Cache Hit Rate**: Objetivo > 60%
- **Cost per 1K requests**: ~$0.02 con cache

## üîí Seguridad

### ‚úÖ Buenas Pr√°cticas Implementadas

1. **API Keys en Environment Variables**: ‚úÖ Nunca en c√≥digo
2. **Firebase Auth**: ‚úÖ Protege endpoints
3. **Rate Limiting**: ‚úÖ Via Vercel AI Gateway
4. **CORS**: ‚úÖ Configurado en Next.js
5. **Logging Seguro**: ‚úÖ Sin exponer datos sensibles

### ‚ö†Ô∏è Importante

- **NUNCA** commitear `.env.local` a Git
- **SIEMPRE** usar `VERCEL_OIDC_TOKEN` en CI/CD
- **ROTAR** API keys cada 90 d√≠as
- **AUDITAR** logs regularmente

## üí∞ Costos Estimados

### Con Vercel AI Gateway (Plan Pro)

| Requests/mes | Sin Cache | Con Cache (60%) | Ahorro |
|--------------|-----------|-----------------|--------|
| 10,000       | $2.00     | $0.80           | 60%    |
| 100,000      | $20.00    | $8.00           | 60%    |
| 1,000,000    | $200.00   | $80.00          | 60%    |

**Vercel Pro**: $20/mes + costos de OpenAI
**Ahorro t√≠pico**: 50-70% en costos de API

## üéì Recursos

- [Vercel AI SDK Docs](https://sdk.vercel.ai/docs)
- [Vercel AI Gateway](https://vercel.com/docs/ai/ai-gateway)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [Firebase + Vercel](https://vercel.com/guides/firebase)

## üìû Soporte

Si encuentras problemas:
1. Revisar logs: `vercel logs`
2. Ver [ISSUES_TRACKER.md](/ISSUES_TRACKER.md)
3. Contactar: [Vercel Support](https://vercel.com/support)

---

**Sistema CHRONOS** - Powered by Vercel AI Gateway üöÄ
