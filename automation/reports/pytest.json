{"created": 1764441300.7480042, "duration": 0.06141495704650879, "exitcode": 0, "root": "/workspaces/v0-crypto-dashboard-design", "environment": {}, "summary": {"passed": 6, "total": 6, "collected": 6}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "evaluation", "type": "Dir"}]}, {"nodeid": "evaluation/datasets", "outcome": "passed", "result": []}, {"nodeid": "evaluation/evaluators", "outcome": "passed", "result": []}, {"nodeid": "evaluation/results", "outcome": "passed", "result": []}, {"nodeid": "evaluation/test_evaluators.py", "outcome": "passed", "result": [{"nodeid": "evaluation/test_evaluators.py::test_intent_detection", "type": "Function", "lineno": 19}, {"nodeid": "evaluation/test_evaluators.py::test_business_logic", "type": "Function", "lineno": 72}, {"nodeid": "evaluation/test_evaluators.py::test_form_autofill", "type": "Function", "lineno": 152}, {"nodeid": "evaluation/test_evaluators.py::test_kpi_accuracy", "type": "Function", "lineno": 221}, {"nodeid": "evaluation/test_evaluators.py::test_report_quality", "type": "Function", "lineno": 262}, {"nodeid": "evaluation/test_evaluators.py::test_user_learning", "type": "Function", "lineno": 302}]}, {"nodeid": "evaluation/test_forms_complete.py::TestResult", "outcome": "passed", "result": []}, {"nodeid": "evaluation/test_forms_complete.py", "outcome": "passed", "result": [{"nodeid": "evaluation/test_forms_complete.py::TestResult", "type": "Class"}]}, {"nodeid": "evaluation", "outcome": "passed", "result": [{"nodeid": "evaluation/datasets", "type": "Dir"}, {"nodeid": "evaluation/evaluators", "type": "Package"}, {"nodeid": "evaluation/results", "type": "Dir"}, {"nodeid": "evaluation/test_evaluators.py", "type": "Module"}, {"nodeid": "evaluation/test_forms_complete.py", "type": "Module"}]}], "tests": [{"nodeid": "evaluation/test_evaluators.py::test_intent_detection", "lineno": 19, "outcome": "passed", "keywords": ["test_intent_detection", "test_evaluators.py", "evaluation", "v0-crypto-dashboard-design", ""], "setup": {"duration": 0.00034944100025313674, "outcome": "passed"}, "call": {"duration": 0.00031988600039767334, "outcome": "passed", "stdout": "\n==================================================\n\ud83e\uddea Test: Intent Detection Evaluator\n==================================================\n\n  Test 1 - Query Data:\n    Intent Accuracy: 100.00%\n    Overall Score: 100.00%\n    \u2705 PASSED\n\n  Test 2 - Wrong Intent:\n    Intent Accuracy: 0.00%\n    Overall Score: 31.00%\n    \u2705 PASSED\n"}, "teardown": {"duration": 0.0001419850004822365, "outcome": "passed"}}, {"nodeid": "evaluation/test_evaluators.py::test_business_logic", "lineno": 72, "outcome": "passed", "keywords": ["test_business_logic", "test_evaluators.py", "evaluation", "v0-crypto-dashboard-design", ""], "setup": {"duration": 0.00019909100046788808, "outcome": "passed"}, "call": {"duration": 0.00032768100027169567, "outcome": "passed", "stdout": "\n==================================================\n\ud83e\uddea Test: Business Logic Evaluator\n==================================================\n\n  Test 1 - Sale Distribution:\n    Boveda Monte: 100.00%\n    Flete Sur: 100.00%\n    Utilidades: 100.00%\n    Overall: 100.00%\n    \u2705 PASSED\n\n  Test 2 - Capital Calculation:\n    Capital Accuracy: 100.00%\n    \u2705 PASSED\n\n  Test 3 - Wrong Distribution:\n    Overall Accuracy: 73.00%\n    Errors: 2\n    \u2705 PASSED\n"}, "teardown": {"duration": 0.00013557199963543098, "outcome": "passed"}}, {"nodeid": "evaluation/test_evaluators.py::test_form_autofill", "lineno": 152, "outcome": "passed", "keywords": ["test_form_autofill", "test_evaluators.py", "evaluation", "v0-crypto-dashboard-design", ""], "setup": {"duration": 0.00016162099927896634, "outcome": "passed"}, "call": {"duration": 0.000248282000029576, "outcome": "passed", "stdout": "\n==================================================\n\ud83e\uddea Test: Form Autofill Evaluator\n==================================================\n\n  Test 1 - Venta Form:\n    Completion Rate: 100.00%\n    Validation Accuracy: 100.00%\n    Overall Accuracy: 90.00%\n    \u2705 PASSED\n\n  Test 2 - Transferencia Form:\n    Validation Accuracy: 100.00%\n    \u2705 PASSED\n"}, "teardown": {"duration": 0.0001272469999094028, "outcome": "passed"}}, {"nodeid": "evaluation/test_evaluators.py::test_kpi_accuracy", "lineno": 221, "outcome": "passed", "keywords": ["test_kpi_accuracy", "test_evaluators.py", "evaluation", "v0-crypto-dashboard-design", ""], "setup": {"duration": 0.00015531999997620005, "outcome": "passed"}, "call": {"duration": 0.0002552759997342946, "outcome": "passed", "stdout": "\n==================================================\n\ud83e\uddea Test: KPI Accuracy Evaluator\n==================================================\n\n  Test 1 - Sales Dashboard:\n    KPI Accuracy: [{'accuracy': 1.0, 'generated': 100000, 'expected': 100000}, {'accuracy': 0.0, 'error': 'KPI no generado'}, {'accuracy': 1.0, 'generated': 15.0, 'expected': 15.0}, {'accuracy': 1.0, 'generated': 100000, 'expected': 100000}, {'accuracy': 0.0, 'error': 'KPI no generado'}, {'accuracy': 0.0, 'error': 'KPI no generado'}]\n    Visualization Score: 80.00%\n    Overall Accuracy: 57.80%\n    \u2705 PASSED\n"}, "teardown": {"duration": 0.000128629000755609, "outcome": "passed"}}, {"nodeid": "evaluation/test_evaluators.py::test_report_quality", "lineno": 262, "outcome": "passed", "keywords": ["test_report_quality", "test_evaluators.py", "evaluation", "v0-crypto-dashboard-design", ""], "setup": {"duration": 0.00017936399945028825, "outcome": "passed"}, "call": {"duration": 0.00031475600007979665, "outcome": "passed", "stdout": "\n==================================================\n\ud83e\uddea Test: Report Quality Evaluator\n==================================================\n\n  Test 1 - Complete Sales Report:\n    Data Completeness: 100.00%\n    Format Correctness: 100.00%\n    Overall Quality: 81.79%\n    \u2705 PASSED\n"}, "teardown": {"duration": 0.00012757799959217664, "outcome": "passed"}}, {"nodeid": "evaluation/test_evaluators.py::test_user_learning", "lineno": 302, "outcome": "passed", "keywords": ["test_user_learning", "test_evaluators.py", "evaluation", "v0-crypto-dashboard-design", ""], "setup": {"duration": 0.00017807199947128538, "outcome": "passed"}, "call": {"duration": 0.0003391820000615553, "outcome": "passed", "stdout": "\n==================================================\n\ud83e\uddea Test: User Learning Evaluator\n==================================================\n\n  Test 1 - User Patterns:\n    Pattern Detection: 66.67%\n    Engagement Accuracy: 0.00%\n    Overall Effectiveness: 52.33%\n    \u2705 PASSED\n"}, "teardown": {"duration": 0.0001535260007585748, "outcome": "passed"}}], "warnings": [{"message": "cannot collect test class 'TestResult' because it has a __init__ constructor (from: evaluation/test_forms_complete.py)", "category": "PytestCollectionWarning", "when": "collect", "filename": "/workspaces/v0-crypto-dashboard-design/evaluation/test_forms_complete.py", "lineno": 29}, {"message": "Test functions should return None, but evaluation/test_evaluators.py::test_intent_detection returned <class 'bool'>.\nDid you mean to use `assert` instead of `return`?\nSee https://docs.pytest.org/en/stable/how-to/assert.html#return-not-none for more information.", "category": "PytestReturnNotNoneWarning", "when": "runtest", "filename": "/usr/local/python/3.12.1/lib/python3.12/site-packages/_pytest/python.py", "lineno": 170}, {"message": "Test functions should return None, but evaluation/test_evaluators.py::test_business_logic returned <class 'bool'>.\nDid you mean to use `assert` instead of `return`?\nSee https://docs.pytest.org/en/stable/how-to/assert.html#return-not-none for more information.", "category": "PytestReturnNotNoneWarning", "when": "runtest", "filename": "/usr/local/python/3.12.1/lib/python3.12/site-packages/_pytest/python.py", "lineno": 170}, {"message": "Test functions should return None, but evaluation/test_evaluators.py::test_form_autofill returned <class 'bool'>.\nDid you mean to use `assert` instead of `return`?\nSee https://docs.pytest.org/en/stable/how-to/assert.html#return-not-none for more information.", "category": "PytestReturnNotNoneWarning", "when": "runtest", "filename": "/usr/local/python/3.12.1/lib/python3.12/site-packages/_pytest/python.py", "lineno": 170}, {"message": "Test functions should return None, but evaluation/test_evaluators.py::test_kpi_accuracy returned <class 'bool'>.\nDid you mean to use `assert` instead of `return`?\nSee https://docs.pytest.org/en/stable/how-to/assert.html#return-not-none for more information.", "category": "PytestReturnNotNoneWarning", "when": "runtest", "filename": "/usr/local/python/3.12.1/lib/python3.12/site-packages/_pytest/python.py", "lineno": 170}, {"message": "Test functions should return None, but evaluation/test_evaluators.py::test_report_quality returned <class 'bool'>.\nDid you mean to use `assert` instead of `return`?\nSee https://docs.pytest.org/en/stable/how-to/assert.html#return-not-none for more information.", "category": "PytestReturnNotNoneWarning", "when": "runtest", "filename": "/usr/local/python/3.12.1/lib/python3.12/site-packages/_pytest/python.py", "lineno": 170}, {"message": "Test functions should return None, but evaluation/test_evaluators.py::test_user_learning returned <class 'bool'>.\nDid you mean to use `assert` instead of `return`?\nSee https://docs.pytest.org/en/stable/how-to/assert.html#return-not-none for more information.", "category": "PytestReturnNotNoneWarning", "when": "runtest", "filename": "/usr/local/python/3.12.1/lib/python3.12/site-packages/_pytest/python.py", "lineno": 170}]}